{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "root_path = R'C:\\Users\\18779\\Desktop\\SummerCourse'\r\n",
    "root_path_local = R'C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝地方法规库批量下载2021.08.21. 12.05.11'\r\n",
    "root_path_center = R'C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝中央法规库批量下载2021.08.21. 12.07.31' \r\n",
    "root_path_local_list = os.listdir(root_path_local)\r\n",
    "root_path_center_list = os.listdir(root_path_center)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import jieba\r\n",
    "def solve(path_name_pairs):\r\n",
    "    excludes = {} # 定义例外的词\r\n",
    "    word_list = []\r\n",
    "    for pair in path_name_pairs:\r\n",
    "        root_path = pair[0]\r\n",
    "        name_list = pair[1]\r\n",
    "        print(root_path)\r\n",
    "        for name in name_list:\r\n",
    "            txt_name = name\r\n",
    "            txt_path = os.path.join(root_path, txt_name)\r\n",
    "            txt = open(txt_path, \"r\", encoding='utf-8').read()\r\n",
    "            words = jieba.lcut(txt)\r\n",
    "            word_list.append(words)\r\n",
    "\r\n",
    "    counts = {}\r\n",
    "    for words in word_list:\r\n",
    "        for word in words:\r\n",
    "            if len(word) == 1:  # 排除单个字符的分词结果\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                counts[word] = counts.get(word, 0) + 1\r\n",
    "        for word in excludes:\r\n",
    "            del (counts[word])\r\n",
    "    items = list(counts.items())\r\n",
    "    items.sort(key=lambda x: x[1], reverse=True)\r\n",
    "    freq_dict = {}\r\n",
    "    word_list = []\r\n",
    "    for i in range(10):\r\n",
    "        word, count = items[i]\r\n",
    "        word_list.append(word)\r\n",
    "        freq_dict[word] = count\r\n",
    "        print(\"{:*<10}{:->5}\".format(word, count))\r\n",
    "    return freq_dict, word_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "path_name_pairs = [[root_path_local, root_path_local_list], [root_path_center, root_path_center_list]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "excludes = {} # 定义例外的词\r\n",
    "word_list = []\r\n",
    "words_dict_list = []\r\n",
    "for pair in path_name_pairs:\r\n",
    "    root_path = pair[0]\r\n",
    "    name_list = pair[1]\r\n",
    "    print(root_path)\r\n",
    "    for name in name_list:\r\n",
    "        txt_name = name\r\n",
    "        txt_path = os.path.join(root_path, txt_name)\r\n",
    "        txt = open(txt_path, \"r\", encoding='utf-8').read()\r\n",
    "        words = jieba.lcut(txt)\r\n",
    "        word_list.append(words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝地方法规库批量下载2021.08.21. 12.05.11\n",
      "C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝中央法规库批量下载2021.08.21. 12.07.31\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(word_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for words in word_list:\r\n",
    "    single_counts = {}\r\n",
    "    for word in words:\r\n",
    "        if len(word) == 1:  # 排除单个字符的分词结果\r\n",
    "            continue\r\n",
    "        else:\r\n",
    "            single_counts[word] = single_counts.get(word, 0) + 1\r\n",
    "    for word in excludes:\r\n",
    "        del (single_counts[word])\r\n",
    "    words_dict_list.append(single_counts)\r\n",
    "# items = list(counts.items())\r\n",
    "# items.sort(key=lambda x: x[1], reverse=True)\r\n",
    "# freq_dict = {}\r\n",
    "# for i in range(100):\r\n",
    "#     word, count = items[i]\r\n",
    "#     freq_dict[word] = count\r\n",
    "#     # print(\"{:*<10}{:->5}\".format(word, count))\r\n",
    "# print(freq_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "f, w = solve(path_name_pairs)\r\n",
    "print(w[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝地方法规库批量下载2021.08.21. 12.05.11\n",
      "C:\\Users\\18779\\Desktop\\SummerCourse\\北大法宝中央法规库批量下载2021.08.21. 12.07.31\n",
      "美育********-9802\n",
      "学校********-5154\n",
      "艺术********-3786\n",
      "课程********-2383\n",
      "学生********-2139\n",
      "教育********-2071\n",
      "工作********-1988\n",
      "教师********-1890\n",
      "活动********-1615\n",
      "发展********-1517\n",
      "['美育', '学校', '艺术', '课程', '学生', '教育', '工作', '教师', '活动', '发展']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import numpy as np\r\n",
    "num_keywords = 10\r\n",
    "num_papers = len(root_path_local_list) + len(root_path_center_list)\r\n",
    "print(num_papers)\r\n",
    "key_words_list = w[:10]\r\n",
    "word_mat = np.zeros((10, num_papers))\r\n",
    "len(words_dict_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "96\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for i in range(num_papers):\r\n",
    "    tem_word_dict = words_dict_list[i]\r\n",
    "    for j, keyword in enumerate(key_words_list):\r\n",
    "        if keyword in tem_word_dict.keys():\r\n",
    "            word_mat[j, i] = tem_word_dict[keyword]\r\n",
    "print(word_mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 81.  40.  21.  11.  42.  36.  20.   9.  28.]\n",
      " [ 72.   0.  21.  51.  16.  22.   0.   0.   0.]\n",
      " [ 38.  17.   1.  58.   6.  16.  16.   0.  11.]\n",
      " [ 66.   9.   3.  68.   1.   5.   0.   1.   6.]\n",
      " [  2.  47.   0.   2.  42.  43.   0.   1.   2.]\n",
      " [  0.   0.   0. 101.   0.   0.   0.   0.   0.]\n",
      " [ 27.   7.   9.   3.   7.  13.   7.   3.  11.]\n",
      " [ 13.  33.   1.   4.  17.   6.   2.   9.   1.]\n",
      " [ 11.   7.   9.   0.   4.   8.  16.   0.  22.]\n",
      " [ 26.   4.   0.  17.   1.   5.   5.   0.  10.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "np.sum(word_mat, axis=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([288., 182., 163., 159., 139., 101.,  87.,  86.,  77.,  68.])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "np.savetxt('word_mat.csv', word_mat,delimiter=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('jidi': conda)"
  },
  "interpreter": {
   "hash": "4a9385d0b2be9552c08a506893e778d72d726c27ac8ec1366334dbb63251a869"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}